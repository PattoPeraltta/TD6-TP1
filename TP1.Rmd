```{r message=FALSE, warning=FALSE}
# Librerias
library(readr)
library(dplyr)
library(ggplot2)
library(pROC)
library(caret)
library(rpart)

# Semilla
set.seed(20250818)
```

## Sección 1: Introducción al problema

### Descripción del conjunto de datos

El conjunto de datos seleccionado corresponde a la **campaña de marketing de una institución bancaria de Portugal**, publicado en el *UCI Machine Learning Repository*. Contiene **45.211 observaciones** y **17 variables predictoras**, que incluyen tanto atributos **numéricos** (edad, duración de la última llamada, balance de la cuenta, entre otros) como **categóricos** (profesión, estado civil, nivel educativo, tipo de vivienda, canal de contacto, mes de contacto, etc.).

La variable objetivo es **binaria**: indica si el cliente **aceptó (yes)** o **rechazó (no)** suscribirse a un depósito a plazo luego de la campaña de marketing. Este problema se formula como una tarea de **clasificación binaria**, donde el objetivo es predecir la propensión del cliente a aceptar la oferta bancaria en base a sus características sociodemográficas y al historial de interacciones con el banco.

### Justificación para el uso de árboles de decisión

La elección de este conjunto de datos es especialmente adecuada para aplicar **árboles de decisión** y métodos derivados (Random Forests, Gradient Boosted Trees), debido a:

1.  **Mezcla de variables**: los árboles pueden manejar de manera natural tanto predictores numéricos como categóricos sin requerir transformaciones complejas.
2.  **Relaciones no lineales y reglas complejas**: la decisión de un cliente no depende de una regla simple (ej., "si edad \> 30, entonces sí"), sino de la interacción entre múltiples factores. Los árboles permiten modelar estas interacciones mediante divisiones jerárquicas.
3.  **Interpretabilidad**: en un contexto bancario, es valioso explicar por qué un modelo predice que un cliente aceptará o no la campaña. Los árboles permiten obtener reglas claras y comprensibles.
4.  **Escalabilidad**: el dataset tiene un tamaño lo suficientemente grande para evaluar el desempeño de modelos complejos, pero no excesivo como para impedir un train eficiente.

En resumen, este conjunto de datos no solo plantea un problema realista e importante de clasificación binaria, sino que también se ajusta adecuadamente a las capacidades de los árboles de decisión, permitiendo explorar tanto sus poderes predictivo y capacidades interpretativas.

## Sección 2: Preparación de los datos

### Carga del dataset

```{r message=FALSE, warning=FALSE}

# Cargar dataset (suponiendo que el archivo se llama bank.csv)
bank <- read.csv("bank.csv", sep = ";")

# Ver estructura inicial
str(bank)

# Variable objetivo (binaria: yes/no)
table(bank$y)

```

### Analisis exploratorio

```{r message=FALSE, warning=FALSE}

# Resumen general de variables numéricas
summary(select_if(bank, is.numeric))

# Frecuencias de algunas variables categóricas clave
table(bank$job)
table(bank$education)

# Distribución de la edad de los clientes (grafico)
ggplot(bank, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
  labs(x = "Edad", y = "Frecuencia")

# Comparación de una variable categórica con la variable objetivo
ggplot(bank, aes(x = job, fill = y)) +
  geom_bar(position = "fill") +
  labs(title = "Proporción de aceptación del depósito según ocupación",
       x = "Ocupación", y = "Proporción") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Comentarios sobre los datos:

-   **Edad**: la mayoría de los clientes se concentran entre los 30 y 50 años, con algunos outliers en edades más altas.

-   **Ocupación**: existen diferencias notorias en la tasa de aceptación de la campaña según el tipo de trabajo; por ejemplo, clientes en sectores administrativos tienden a tener una proporción distinta a los desempleados o estudiantes.

-   **Balance de cuenta y duración de llamada**: presentan gran variabilidad y podrían ser predictores relevantes para el modelo.

-   **Desbalance de clases**: la variable objetivo está desbalanceada (muchos más *no* que *sí*), lo cual será importante a considerar en la modelización.

## Sección 3: Construcción de un árbol de decisión básico

```{r message=FALSE, warning=FALSE}




n <- nrow(bank)

# límites
max_valid <- floor(0.15 * n)
max_test  <- floor(0.15 * n)

# listas de índices
idx_entrenamiento <- integer(0)
idx_validacion    <- integer(0)
idx_testeo        <- integer(0)

for (i in 1:n) {
  r <- runif(1)  # número aleatorio entre 0 y 1

  if (r < 0.15 && length(idx_validacion) < max_valid) {
    idx_validacion <- c(idx_validacion, i)
  } else if (r < 0.30 && length(idx_testeo) < max_test) {
    idx_testeo <- c(idx_testeo, i)
  } else {
    idx_entrenamiento <- c(idx_entrenamiento, i)
  }
}

# subconjuntos finales
entrenamiento <- bank[idx_entrenamiento, , drop = FALSE]
validacion    <- bank[idx_validacion,    , drop = FALSE]
testeo        <- bank[idx_testeo,        , drop = FALSE]

```

```{r message=FALSE, warning=FALSE}

# Entrenar árbol básico con defaults
arbol_basico <- rpart(
  y ~ .,
  data   = entrenamiento,
  method = "class"
)
```
#### Hiperparámetros por defecto de `rpart`

- **`minsplit = 20`**  
  Un nodo debe tener **al menos 20** observaciones para que se intente un split. Limita la fragmentación temprana y reduce el sobreajuste en nodos muy chicos.

- **`minbucket = round(minsplit/3)` → ~7**  
  Tamaño mínimo de **cada hoja**. Con el valor por defecto de `minsplit`, cada hoja terminal debe tener ~7 observaciones. Evita hojas ínfimas e inestables.

- **`cp = 0.01`** (complexity parameter)  
  Solo se aceptan splits que reduzcan el error relativo **≥ 1%**. Favorece árboles más chicos y acelera el ajuste. Luego se genera la secuencia de podas según `cp`.

- **`xval = 10`**  
  **Validación cruzada 10-fold interna** para estimar el error y elegir el nivel de poda (en la tabla de `cp`).

- **`maxdepth = 30`**  
  Profundidad máxima muy alta (prácticamente sin tope en la práctica). El control real de complejidad lo imponen `cp`, `minsplit` y `minbucket`.

- **`maxcompete = 4`**  
  Guarda hasta **4 splits competidores** por nodo (no afecta el ajuste; es metadato útil para inspección).

- **`maxsurrogate = 5`**  
  Guarda hasta **5 variables sustitutas** por nodo para manejar **valores faltantes**.

- **`usesurrogate = 2`**  
  Si falta la variable del split principal, **usa surrogates en orden**; si tampoco están disponibles, envía el caso por la **rama mayoritaria**.

- **`surrogatestyle = 0`**  
  El “mejor” surrogate se elige por **número total de aciertos** (penaliza variables con muchos NA).

- (**Clasificación**) **`split = "gini"`**, **`prior`** proporcionales a las **frecuencias de clase observadas** y **`loss`** con costo uniforme de error (0 en la diagonal y 1 fuera de la diagonal).  
  Implica que los cortes minimizan **impureza Gini**, asumiendo las prevalencias del dataset y costos de clasificación iguales, salvo que se especifiquen otros.


```{r message=FALSE, warning=FALSE}
library(rpart.plot)
# Visualización
rpart.plot(arbol_basico, type = 2, extra = 106, box.palette = "GnBu")

```

**Altura observada:** 5 niveles (raíz + 4 divisiones).  

1) **Raíz — `duration < 477 s`**  
   Divide “llamadas cortas” vs “largas”. Es el corte más informativo: las cortas concentran **NO**, las largas elevan la chance de **YES**.

2) **Rama izquierda (`duration < 477`)**  
   - Siguientes cortes: **`poutcome`** (resultados previos de campaña), **`month`** y umbrales más bajos de **`duration`** (≈ 180 s).  
   - Interpretación: **llamadas muy cortas** y **sin buen antecedente** tienden a **NO**. Los ajustes con `month` refinan pequeños subgrupos.

3) **Rama derecha (`duration ≥ 477`)**  
   - Segundo umbral de **`duration`**: **≈ 765 s** separa **llamadas largas** (alta probabilidad de **YES**) de las **intermedias**.  
   - En la franja intermedia, la decisión se afina con **`job`**, **`marital`**, y en menor medida **`month/day`**:
     - Ocupaciones no profesionales y `marital = married` empujan a **NO**.  
     - Ocupaciones profesionales/servicios y otros estados civiles elevan la chance de **YES**.


## 4. Evaluación del árbol de decisión básico
```{r}
# Normalización de niveles en los tres splits
for (nm in c("entrenamiento", "validacion", "testeo")) {
  if (exists(nm)) {
    tmp <- get(nm)
    if (!is.factor(tmp$y)) tmp$y <- as.factor(tmp$y)
    if (all(c("no", "yes") %in% levels(tmp$y))) {
      tmp$y <- factor(tmp$y, levels = c("no", "yes"))
    }
    assign(nm, tmp)
  }
}

# Chequeos
stopifnot(exists("arbol_basico"), exists("testeo"))
stopifnot("y" %in% names(testeo))
stopifnot(is.factor(testeo$y))

# Predicciones en testeo
pred_class <- predict(arbol_basico, newdata = testeo, type = "class")
pred_class <- factor(pred_class, levels = levels(testeo$y))

pred_prob_mat <- predict(arbol_basico, newdata = testeo, type = "prob")
pos_col <- if ("yes" %in% colnames(pred_prob_mat)) "yes" else tail(colnames(pred_prob_mat), 1)
pred_prob <- pred_prob_mat[, pos_col]

# Matriz de confusión y métricas
matriz_conf <- caret::confusionMatrix(pred_class, testeo$y, positive = "yes")

accuracy  <- matriz_conf$overall["Accuracy"]
precision <- matriz_conf$byClass["Precision"]
recall    <- matriz_conf$byClass["Recall"]
f1        <- matriz_conf$byClass["F1"]

# --- Gráficos: Matriz de confusión (conteos y proporciones) ------------------

# Conteos
cm_tbl <- as.table(matriz_conf$table)
cm_df <- as.data.frame(cm_tbl)
names(cm_df) <- c("real", "pred", "freq")

ggplot(cm_df, aes(x = real, y = pred, fill = freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = freq), size = 4) +
  scale_fill_gradient(low = "lightblue", high = "steelblue") +
  labs(
    title = "Matriz de confusión (conteos)",
    x = "Valor real",
    y = "Predicción",
    fill = "Frecuencia"
  ) +
  theme_minimal()

# Proporciones por clase real
cm_prop <- dplyr::group_by(cm_df, real)
cm_prop <- dplyr::mutate(cm_prop, prop = freq / sum(freq))
cm_prop <- dplyr::ungroup(cm_prop)

ggplot(cm_prop, aes(x = real, y = pred, fill = prop)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * prop)), size = 4) +
  scale_fill_gradient(low = "lavender", high = "purple") +
  labs(
    title = "Matriz de confusión (proporciones por real)",
    x = "Valor real",
    y = "Predicción",
    fill = "Proporción"
  ) +
  theme_minimal()


# ROC y AUC
roc_curve <- pROC::roc(
  testeo$y,
  pred_prob,
  levels = c("no", "yes"),
  direction = "<"
)
auc_value <- pROC::auc(roc_curve)

# Tabla resumen
resumen <- data.frame(
  Metrica = c("Accuracy", "Precision", "Recall", "F1", "AUC-ROC"),
  Valor   = c(
    as.numeric(accuracy),
    as.numeric(precision),
    as.numeric(recall),
    as.numeric(f1),
    as.numeric(auc_value)
  )
)
knitr::kable(resumen, digits = 4, caption = "Punto 4 — Métricas (Test)")


plot(roc_curve, lwd = 2, main = "Curva ROC — Árbol básico (Test)")
abline(a = 0, b = 1, lty = 2)
```

### Interpretación de resultados

Al evaluar el árbol de decisión básico en el conjunto de testeo se observa
que el modelo alcanza un **accuracy de aproximadamente 92%**, un valor
elevado y aparentemente satisfactorio a primera vista. Sin embargo, al
analizar con mayor detalle la matriz de confusión se advierte que este buen
desempeño global está muy influido por el **desbalance de clases**: la
mayoría de los clientes pertenece a la clase negativa (“no”), por lo que un
modelo que siempre predijera “no” alcanzaría un **No Information Rate
(NIR) del 90%**. Esto significa que la mejora real sobre una estrategia
trivial es más reducida de lo que sugiere el valor bruto del accuracy, e
incluso la prueba de significancia muestra que la diferencia respecto al NIR
no es concluyente al 5% de significancia.

La interpretación cambia si se examinan otras métricas específicas de la
clase positiva. La **precisión (precision)** alcanza un 64%, lo que indica
que cuando el modelo se arriesga a predecir que un cliente aceptará el
depósito (“yes”), tiene más de la mitad de probabilidades de estar en lo
cierto. Sin embargo, la **sensibilidad (recall)** es mucho más baja, alrededor
de 41%, lo que significa que el árbol deja escapar a más de la mitad de los
clientes que efectivamente aceptan la oferta. Esto se traduce en un número
importante de falsos negativos (39 en el testeo), lo que podría ser
problemático en un contexto de marketing donde detectar a los posibles
clientes interesados suele ser más importante que evitar falsos positivos. El
**F1-score**, que combina precisión y recall en una sola medida, queda en
torno a 0.50, lo que confirma un equilibrio modesto y refleja la dificultad
del modelo para captar de manera consistente la clase minoritaria.

En contraste, la **especificidad del modelo es muy alta (97.5%)**, lo cual
significa que el árbol distingue muy bien a los clientes que no contratarán
el depósito, cometiendo muy pocos falsos positivos. Esta asimetría entre
sensibilidad y especificidad está en línea con lo que se observa en la prueba
de McNemar, que arroja un p-valor significativo indicando que los errores
no se distribuyen de manera balanceada: el modelo tiende claramente a
equivocarse más en los positivos que en los negativos.

Finalmente, la **curva ROC y el AUC confirman la existencia de señal
predictiva**. El área bajo la curva se ubica en 0.79, lo que indica que, si se
toma al azar un cliente que aceptó y uno que rechazó la oferta, en casi ocho
de cada diez casos el modelo asigna una probabilidad mayor al cliente
positivo que al negativo. Este valor refleja que, más allá del umbral de
decisión fijo que usa `rpart` (basado en la mayoría de la hoja, equivalente a
0.5), las probabilidades generadas contienen información útil y podrían
aprovecharse para mejorar el recall ajustando el umbral de clasificación.
